{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "import time\n",
    "tqdm.pandas(mininterval = 3)\n",
    "from pandas.api.types import infer_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define column SCIENCE as str type becuase the shortcut for computer science (inf) get interpreted as infinity/float which causes a mixed dtype\n",
    "# changing all columns to category type to reduce memory usage if possible/makes sense\n",
    "\n",
    "df_combined = pd.read_csv(r\"E:\\Organization_Project\\files\\Preprocessed_Combined_Meta_Dataset.csv\", dtype={\"SCIENCE\": str})\n",
    "df_combined[\"SCIENCE\"] = df_combined[\"SCIENCE\"].astype(\"category\")\n",
    "df_combined[\"KEYWORD\"] = df_combined[\"KEYWORD\"].astype(\"category\")\n",
    "df_combined[\"JOURNAL\"] = df_combined[\"JOURNAL\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>ID</th>\n",
       "      <th>JOURNAL</th>\n",
       "      <th>KEYWORD</th>\n",
       "      <th>SCIENCE</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>Li X</td>\n",
       "      <td>35655310.0</td>\n",
       "      <td>Journal of experimental &amp; clinical cancer rese...</td>\n",
       "      <td>Biochemistry[Mesh Terms]</td>\n",
       "      <td>che</td>\n",
       "      <td>background  micrornas isomirs play important r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>Kirk P</td>\n",
       "      <td>35655273.0</td>\n",
       "      <td>BMC biology</td>\n",
       "      <td>Biochemistry[Mesh Terms]</td>\n",
       "      <td>che</td>\n",
       "      <td>background  major route cell-to-cell signallin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Wong EL</td>\n",
       "      <td>35655449.0</td>\n",
       "      <td>Frontiers in public health</td>\n",
       "      <td>Biochemistry[Mesh Terms]</td>\n",
       "      <td>che</td>\n",
       "      <td>background  virtually invasive cervical cancer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Huang Y</td>\n",
       "      <td>35654504.0</td>\n",
       "      <td>Journal of environmental sciences (China)</td>\n",
       "      <td>Biochemistry[Mesh Terms]</td>\n",
       "      <td>che</td>\n",
       "      <td>nanoscale bismuth oxyiodide widely studied app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>Tayal U</td>\n",
       "      <td>35654493.0</td>\n",
       "      <td>Journal of the American College of Cardiology</td>\n",
       "      <td>Biochemistry[Mesh Terms]</td>\n",
       "      <td>che</td>\n",
       "      <td>background  dilated cardiomyopathy final commo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE   AUTHOR          ID  \\\n",
       "0  2022-06-01     Li X  35655310.0   \n",
       "1  2022-06-01   Kirk P  35655273.0   \n",
       "2  2022-01-01  Wong EL  35655449.0   \n",
       "3  2022-11-01  Huang Y  35654504.0   \n",
       "4  2022-06-01  Tayal U  35654493.0   \n",
       "\n",
       "                                             JOURNAL  \\\n",
       "0  Journal of experimental & clinical cancer rese...   \n",
       "1                                        BMC biology   \n",
       "2                         Frontiers in public health   \n",
       "3          Journal of environmental sciences (China)   \n",
       "4      Journal of the American College of Cardiology   \n",
       "\n",
       "                    KEYWORD SCIENCE  \\\n",
       "0  Biochemistry[Mesh Terms]     che   \n",
       "1  Biochemistry[Mesh Terms]     che   \n",
       "2  Biochemistry[Mesh Terms]     che   \n",
       "3  Biochemistry[Mesh Terms]     che   \n",
       "4  Biochemistry[Mesh Terms]     che   \n",
       "\n",
       "                                            Abstract  \n",
       "0  background  micrornas isomirs play important r...  \n",
       "1  background  major route cell-to-cell signallin...  \n",
       "2  background  virtually invasive cervical cancer...  \n",
       "3  nanoscale bismuth oxyiodide widely studied app...  \n",
       "4  background  dilated cardiomyopathy final commo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3237571, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in edlinger dict\n",
    "# creating sentiment Analyzer object\n",
    "SIA = SentimentIntensityAnalyzer()\n",
    "\n",
    "edlinger_dict = {\n",
    "\n",
    " \t'beneficial': 1.9,  \n",
    "        'benefit': 2.0,  \n",
    "    'benefits': 1.6,  \n",
    "    'better': 1.9, \n",
    "    \t'effectively': 1.9,  \n",
    "     'efficient': 1.8,\n",
    "        'excellent': 2.7,\n",
    "    'greater': 1.5, \n",
    "            'help': 1.7, \n",
    "    'importance': 1.5,     \n",
    "    'important': 0.8,\n",
    "        'improve': 1.9,    \n",
    "    'improved': 2.1,  \n",
    "    \t'improvement': 2.0, \n",
    "    'improvements': 1.3,\n",
    "        'improving': 1.8,\n",
    "    'increase': 1.3, \n",
    "         'increased': 1.1,\n",
    "    'interest': 2.0,    \n",
    "        'novel': 1.3, \n",
    "        'optimal': 1.5,  \n",
    "     'opportunity': 1.8,\n",
    "        'promise': 1.3,  \n",
    "        'progress': 1.8,   \n",
    "    'significance': 1.1,     \n",
    "    'significantly': 0.8,\n",
    "        'strong': 2.3,\n",
    "        'strongly': 1.1,    \n",
    "    'successfully': 2.2,\n",
    "            'supported': 1.3, \n",
    "    'supporting': 1.9,\n",
    "        'supports': 1.5,    \n",
    "    'useful': 1.9,\n",
    "        'valuable': 2.1, \n",
    "    'well': 1.1\n",
    "}\n",
    "\n",
    "SIA.lexicon = {}\n",
    "SIA.lexicon.update(edlinger_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SIA.lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function calculates sentiment score for whole abstracts\n",
    "\n",
    "def whole_sentiment(df):\n",
    "\n",
    "    df[\"pos_whole\"] = df[\"Abstract\"].progress_apply(lambda x: SIA.polarity_scores(x))\n",
    "    df[\"neg_whole\"] = df[\"pos_whole\"].apply(lambda x: x[\"neg\"])\n",
    "    df[\"neu_whole\"] = df[\"pos_whole\"].apply(lambda x: x[\"neu\"])\n",
    "    df[\"compound_whole\"] = df[\"pos_whole\"].apply(lambda x: x[\"compound\"])\n",
    "    df[\"pos_whole\"] = df[\"pos_whole\"].apply(lambda x: x[\"pos\"])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3237571/3237571 [56:05<00:00, 961.95it/s] \n"
     ]
    }
   ],
   "source": [
    "# the above function is applied to the dataframe\n",
    "# and the file is saved to the entered path\n",
    "\n",
    "df_combined_full_vader = whole_sentiment(df_combined)\n",
    "df_combined_full_vader[[\"DATE\",\"pos_whole\",\n",
    "            \"neg_whole\", \"neu_whole\", \"compound_whole\",\"ID\"]].to_csv(\n",
    "            r\"E:\\Organization_Project\\files\\df_vader_whole_meta_combined.csv\",\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function splits the abstracts into three\n",
    "# parts and calculates sentiment scores for each third\n",
    "def split_string(s):\n",
    "    parts = s.split()\n",
    "    return ' '.join(parts[:len(parts)//3]), ' '.join(parts[len(parts)//3:((len(parts)//3)*2)]), ' '.join(parts[((len(parts)//3)*2):])\n",
    "\n",
    "def split_sentiment(df):\n",
    "\n",
    "    #spliting abstract and saving each third into a new column\n",
    "    df['split_abstracts_1'], df['split_abstracts_2'], df['split_abstracts_3'] = zip(*df['Abstract'].progress_apply(split_string))\n",
    "\n",
    "    # old code, less efficient\n",
    "    # df[\"Abstract\"] = df[\"Abstract\"].progress_apply(lambda x: x.split())\n",
    "    # splitting abstracts into thirds\n",
    "    # df[\"split_abstracts_1\"] = df[\"Abstract\"].progress_apply(lambda x: \" \".join(x[:len(x)//3]))\n",
    "    # df[\"split_abstracts_2\"] = df[\"Abstract\"].progress_apply(lambda x: \" \".join(x[len(x)//3:((len(x)//3)*2)]))\n",
    "    # df[\"split_abstracts_3\"] = df[\"Abstract\"].progress_apply(lambda x: \" \".join(x[((len(x)//3)*2):]))\n",
    "\n",
    "    # calcualting sentiment scores for the split abstracts\n",
    "    df[\"pos_1\"] = df[\"split_abstracts_1\"].progress_apply(lambda x: SIA.polarity_scores(x))\n",
    "    df[\"neg_1\"] = df[\"pos_1\"].apply(lambda x: x[\"neg\"])\n",
    "    df[\"neu_1\"] = df[\"pos_1\"].apply(lambda x: x[\"neu\"])\n",
    "    df[\"compound_1\"] = df[\"pos_1\"].apply(lambda x: x[\"compound\"])\n",
    "    df[\"pos_1\"] = df[\"pos_1\"].apply(lambda x: x[\"pos\"])\n",
    "\n",
    "    df[\"pos_2\"] = df[\"split_abstracts_2\"].progress_apply(lambda x: SIA.polarity_scores(x))\n",
    "    df[\"neg_2\"] = df[\"pos_2\"].apply(lambda x: x[\"neg\"])\n",
    "    df[\"neu_2\"] = df[\"pos_2\"].apply(lambda x: x[\"neu\"])\n",
    "    df[\"compound_2\"] = df[\"pos_2\"].apply(lambda x: x[\"compound\"])\n",
    "    df[\"pos_2\"] = df[\"pos_2\"].apply(lambda x: x[\"pos\"])\n",
    "\n",
    "    df[\"pos_3\"] = df[\"split_abstracts_3\"].progress_apply(lambda x: SIA.polarity_scores(x))\n",
    "    df[\"neg_3\"] = df[\"pos_3\"].apply(lambda x: x[\"neg\"])\n",
    "    df[\"neu_3\"] = df[\"pos_3\"].apply(lambda x: x[\"neu\"])\n",
    "    df[\"compound_3\"] = df[\"pos_3\"].apply(lambda x: x[\"compound\"])\n",
    "    df[\"pos_3\"] = df[\"pos_3\"].apply(lambda x: x[\"pos\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3237571/3237571 [00:52<00:00, 61160.67it/s]\n",
      "100%|██████████| 3237571/3237571 [22:23<00:00, 2409.31it/s]\n",
      "100%|██████████| 3237571/3237571 [21:28<00:00, 2512.56it/s]\n",
      "100%|██████████| 3237571/3237571 [20:57<00:00, 2575.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# the above function is applied to the dataframe\n",
    "# and the file is saved to the entered path\n",
    "df_combined_full_vader = split_sentiment(df_combined)\n",
    "df_combined_full_vader[[\"DATE\",\n",
    "             \"pos_1\", \"pos_2\", \"pos_3\", \"neg_1\", \"neg_2\",\n",
    "             \"neg_3\", \"neu_1\", \"neu_2\", \"neu_3\", \"compound_1\",\n",
    "             \"compound_2\", \"compound_3\", \"ID\"]].to_csv(\n",
    "             r\"E:\\Organization_Project\\files\\df_vader_thirds_meta_combined.csv\",\n",
    "            index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
